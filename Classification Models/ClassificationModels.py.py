# -*- coding: utf-8 -*-
"""Diabetes Prediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Sy9Jzk64TYokGaemMiuNKqu4r-GVyXp0

Importing the Dependencies
1. NumPy
2. Pandas
3. Scikit-Learn
"""

import numpy as np
import pandas as pd
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn import svm
from sklearn.metrics import (
    accuracy_score,
    precision_score,
    recall_score,
    f1_score,
    roc_auc_score,
    roc_curve,
    confusion_matrix,
    ConfusionMatrixDisplay
)
import matplotlib.pyplot as plt

"""Data Collection and Analysis

PIMA Diabetes Dataset from kaggle
"""

# loading the diabetes dataset to a pandas DataFrame
diabetes_dataset = pd.read_csv('diabetes.csv')

import pandas as pd
df = pd.DataFrame()

# printing the first 5 rows of the dataset
diabetes_dataset.head()

# printing the last 5 rows of the dataset
diabetes_dataset.tail()

# To get the number of rows and columns in this dataset
diabetes_dataset.shape

# getting the statistical measures of the data
diabetes_dataset.describe()

diabetes_dataset['Outcome'].value_counts()

"""0 --> Non-Diabetic

1 --> Diabetic
"""

diabetes_dataset.groupby('Outcome').mean()

# separating the data and labels
X = diabetes_dataset.drop(columns = 'Outcome', axis=1)
Y = diabetes_dataset['Outcome']

print(X)

print(Y)

"""HEAT MAP DIAGRAM OF DATASETS"""

import seaborn as sns
import matplotlib.pyplot as plt

# Load dataset (if not already loaded)
df = pd.read_csv('diabetes.csv')

# Compute correlation matrix
correlation_matrix = df.corr()

# Plot heatmap
plt.figure(figsize=(10, 8))
sns.heatmap(correlation_matrix, annot=True, fmt='.2f', cmap='coolwarm', square=True, linewidths=0.5)
plt.title('Correlation Heatmap of Diabetes Dataset', fontsize=14)
plt.xticks(rotation=45)
plt.yticks(rotation=0)
plt.tight_layout()
plt.show()

"""Pair plot of the data"""

import seaborn as sns
import matplotlib.pyplot as plt
import pandas as pd

# Load the dataset (if not already loaded)
df = pd.read_csv('diabetes.csv')

# Optional: Reduce the number of features for better visualization
# You can include all columns, but it may be too dense
selected_columns = ['Glucose', 'BMI', 'Age', 'Insulin', 'BloodPressure', 'Outcome']

# Pair plot with hue set to Outcome
sns.pairplot(df[selected_columns], hue='Outcome', palette='Set1', diag_kind='kde')
plt.suptitle("Pair Plot of Selected Features in Diabetes Dataset", y=1.02)
plt.show()

"""Data Standardization"""

scaler = StandardScaler()

scaler.fit(X)

standardized_data = scaler.transform(X)

print(standardized_data)

X = standardized_data
Y = diabetes_dataset['Outcome']

print(X)
print(Y)

"""Train Test Split"""

X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.2, stratify=Y, random_state=2)

print(X.shape, X_train.shape, X_test.shape)

"""Training the Model"""

classifier = svm.SVC(kernel='linear',probability = True)

#training the support vector Machine Classifier
classifier.fit(X_train, Y_train)

# Predictions
Y_pred = classifier.predict(X_test)
Y_proba = classifier.predict_proba(X_test)[:, 1]  # Needed for ROC AUC

"""Model Evaluation"""

from sklearn.metrics import roc_auc_score

roc_auc = roc_auc_score(Y_test, Y_proba)  # Calculate AUC from the data
fpr, tpr, _ = roc_curve(Y_test, Y_proba)
plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, label=f"SVM (AUC = {roc_auc:.2f})")
plt.plot([0, 1], [0, 1], 'k--', label="Random Guess")
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.title("ROC Curve")
plt.legend()
plt.grid(True)
plt.show()

# Confusion Matrix
cm = confusion_matrix(Y_test, Y_pred)
disp = ConfusionMatrixDisplay(confusion_matrix=cm)
disp.plot()
plt.title("Confusion Matrix")
plt.show()

"""Accuracy Score"""

# accuracy score on the training data
X_train_prediction = classifier.predict(X_train)
training_data_accuracy = accuracy_score(X_train_prediction, Y_train)
training_data_precision = precision_score(X_train_prediction, Y_train)
training_data_f1 = f1_score(X_train_prediction, Y_train)

print('Accuracy score of the training data : ', training_data_accuracy)
print('Precision score of the training data : ', training_data_precision)
print('F1_score score of the training data : ', training_data_f1)

# accuracy score on the test data
X_test_prediction = classifier.predict(X_test)
test_data_accuracy = accuracy_score(X_test_prediction, Y_test)
test_data_precision = precision_score(X_test_prediction, Y_test)
test_data_f1 = f1_score(X_test_prediction, Y_test)

print('Accuracy score of the test data : ', test_data_accuracy)
print('Precision score of the test data : ', test_data_precision)
print('F1_score score of the test data : ', test_data_f1)

input_data = (5,166,72,19,175,25.8,0.587,51)

# changing the input_data to numpy array
input_data_as_numpy_array = np.asarray(input_data)

# reshape the array as we are predicting for one instance
input_data_reshaped = input_data_as_numpy_array.reshape(1,-1)

# standardize the input data
std_data = scaler.transform(input_data_reshaped)
print(std_data)

prediction = classifier.predict(std_data)
print(prediction)

if (prediction[0] == 0):
  print('The person is not diabetic')
else:
  print('The person is diabetic')

"""Now For KNN Model"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import (
    accuracy_score,
    precision_score,
    recall_score,
    f1_score,
    roc_auc_score,
    roc_curve,
    confusion_matrix,
    ConfusionMatrixDisplay,
)

# Load the diabetes dataset
diabetes_dataset = pd.read_csv('diabetes.csv')

# Split data into features and target
X = diabetes_dataset.drop(columns='Outcome', axis=1)
y = diabetes_dataset['Outcome']

# Standardize the features
scaler = StandardScaler()
X = scaler.fit_transform(X)

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, stratify=y, random_state=2
)

# Train the KNN model
knn_model = KNeighborsClassifier(n_neighbors=5)
knn_model.fit(X_train, y_train)

# Make predictions
y_pred = knn_model.predict(X_test)
y_proba = knn_model.predict_proba(X_test)[:, 1]  # For ROC AUC

# Calculate metrics
accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)
roc_auc = roc_auc_score(y_test, y_proba)

# Print metrics
print("Accuracy:", accuracy)
print("Precision:", precision)
print("Recall:", recall)
print("F1 Score:", f1)
print("ROC AUC Score:", roc_auc)

# Plot ROC AUC Curve
fpr, tpr, _ = roc_curve(y_test, y_proba)
plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, label=f"KNN (AUC = {roc_auc:.2f})")
plt.plot([0, 1], [0, 1], 'k--', label="Random guess")
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve')
plt.legend()
plt.grid(True)
plt.show()

# Confusion matrix
cm = confusion_matrix(y_test, y_pred)
disp = ConfusionMatrixDisplay(confusion_matrix=cm)
disp.plot()
plt.title("Confusion Matrix")
plt.show()

"""now based on train data"""

# === Evaluate on Training Data ===
y_train_pred = knn_model.predict(X_train)
y_train_proba = knn_model.predict_proba(X_train)[:, 1]

# Training metrics
train_accuracy = accuracy_score(y_train, y_train_pred)
train_precision = precision_score(y_train, y_train_pred)
train_recall = recall_score(y_train, y_train_pred)
train_f1 = f1_score(y_train, y_train_pred)
train_roc_auc = roc_auc_score(y_train, y_train_proba)

print("\n--- Training Data Evaluation ---")
print("Train Accuracy:", train_accuracy)
print("Train Precision:", train_precision)
print("Train Recall:", train_recall)
print("Train F1 Score:", train_f1)
print("Train ROC AUC Score:", train_roc_auc)

# ROC Curve for training data
fpr_train, tpr_train, _ = roc_curve(y_train, y_train_proba)
plt.figure(figsize=(8, 6))
plt.plot(fpr_train, tpr_train, label=f"KNN Train (AUC = {train_roc_auc:.2f})")
plt.plot([0, 1], [0, 1], 'k--', label="Random guess")
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve (Training Data)')
plt.legend()
plt.grid(True)
plt.show()

# Confusion matrix for training data
cm_train = confusion_matrix(y_train, y_train_pred)
disp_train = ConfusionMatrixDisplay(confusion_matrix=cm_train)
disp_train.plot()
plt.title("Confusion Matrix (Training Data)")
plt.show()

"""Accuracy vs K-Plot

"""

k_values = range(1, 21)
test_accuracies = []
train_accuracies = []

for k in k_values:
    model = KNeighborsClassifier(n_neighbors=k)
    model.fit(X_train, y_train)

    # Test accuracy
    y_test_pred = model.predict(X_test)
    test_accuracies.append(accuracy_score(y_test, y_test_pred))

    # Train accuracy
    y_train_pred = model.predict(X_train)
    train_accuracies.append(accuracy_score(y_train, y_train_pred))

# Plotting both
plt.figure(figsize=(10, 6))
plt.plot(k_values, train_accuracies, marker='o', label='Train Accuracy', color='blue')
plt.plot(k_values, test_accuracies, marker='s', label='Test Accuracy', color='orange')
plt.xlabel('Number of Neighbors (K)')
plt.ylabel('Accuracy')
plt.title('Accuracy vs. K (Train vs Test)')
plt.legend()
plt.grid(True)
plt.show()

# Score on the training data
X_train_prediction = knn_model.predict(X_train)
training_data_accuracy = accuracy_score(X_train_prediction, Y_train)
training_data_precision = precision_score(X_train_prediction, Y_train)
training_data_f1 = f1_score(X_train_prediction, Y_train)

print('Accuracy score of the training data : ', training_data_accuracy)
print('Precision score of the training data : ', training_data_precision)
print('F1_score score of the training data : ', training_data_f1)

# Score on the test data
X_test_prediction = knn_model.predict(X_test)
test_data_accuracy = accuracy_score(X_test_prediction, Y_test)
test_data_precision = precision_score(X_test_prediction, Y_test)
test_data_f1 = f1_score(X_test_prediction, Y_test)

print('Accuracy score of the test data : ', test_data_accuracy)
print('Precision score of the test data : ', test_data_precision)
print('F1_score score of the test data : ', test_data_f1)

"""Now For Logistic Regression

"""

import numpy as np
import pandas as pd
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, precision_score, f1_score

# Load the dataset
diabetes_dataset = pd.read_csv('diabetes.csv')

# Split data into features and target
X = diabetes_dataset.drop(columns='Outcome', axis=1)
y = diabetes_dataset['Outcome']

# Standardize the features
scaler = StandardScaler()
scaler.fit(X)
X = scaler.transform(X)

# Split into train and test sets
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, stratify=y, random_state=2
)

# Train the Logistic Regression model
logreg_model = LogisticRegression(max_iter=1000)
logreg_model.fit(X_train, y_train)

# Score on the training data
X_train_prediction = logreg_model.predict(X_train)
training_data_accuracy = accuracy_score(X_train_prediction, Y_train)
training_data_precision = precision_score(X_train_prediction, Y_train)
training_data_f1 = f1_score(X_train_prediction, Y_train)

print('Accuracy score of the training data : ', training_data_accuracy)
print('Precision score of the training data : ', training_data_precision)
print('F1_score score of the training data : ', training_data_f1)

# Score on the test data
X_test_prediction = logreg_model.predict(X_test)
test_data_accuracy = accuracy_score(X_test_prediction, Y_test)
test_data_precision = precision_score(X_test_prediction, Y_test)
test_data_f1 = f1_score(X_test_prediction, Y_test)

print('Accuracy score of the test data : ', test_data_accuracy)
print('Precision score of the test data : ', test_data_precision)
print('F1_score score of the test data : ', test_data_f1)

"""Now For Random Forest Classifier"""

import numpy as np
import pandas as pd
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, precision_score, f1_score

# Load the diabetes dataset
diabetes_dataset = pd.read_csv('diabetes.csv')

# Split data into features and target
X = diabetes_dataset.drop(columns='Outcome', axis=1)
y = diabetes_dataset['Outcome']

# Standardize the features
scaler = StandardScaler()
scaler.fit(X)
X = scaler.transform(X)

# Split into train and test sets
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, stratify=y, random_state=2
)

# Train the Random Forest Classifier
rf_model = RandomForestClassifier(random_state=2)
rf_model.fit(X_train, y_train)

# Score on the training data
X_train_prediction = rf_model.predict(X_train)
training_data_accuracy = accuracy_score(X_train_prediction, Y_train)
training_data_precision = precision_score(X_train_prediction, Y_train)
training_data_f1 = f1_score(X_train_prediction, Y_train)

print('Accuracy score of the training data : ', training_data_accuracy)
print('Precision score of the training data : ', training_data_precision)
print('F1_score score of the training data : ', training_data_f1)

# Score on the test data
X_test_prediction = rf_model.predict(X_test)
test_data_accuracy = accuracy_score(X_test_prediction, Y_test)
test_data_precision = precision_score(X_test_prediction, Y_test)
test_data_f1 = f1_score(X_test_prediction, Y_test)

print('Accuracy score of the test data : ', test_data_accuracy)
print('Precision score of the test data : ', test_data_precision)
print('F1_score score of the test data : ', test_data_f1)

pip install xgboost

from xgboost import XGBClassifier

xgb_model = XGBClassifier(use_label_encoder=False, eval_metric='logloss')
xgb_model.fit(X_train, y_train)

y_train_pred = xgb_model.predict(X_train)
y_test_pred = xgb_model.predict(X_test)

print("\nðŸ“˜ XGBoost:")
print("Train - Accuracy:", accuracy_score(y_train, y_train_pred))
print("Train - Precision:", precision_score(y_train, y_train_pred))
print("Train - F1 Score:", f1_score(y_train, y_train_pred))
print("Test  - Accuracy:", accuracy_score(y_test, y_test_pred))
print("Test  - Precision:", precision_score(y_test, y_test_pred))
print("Test  - F1 Score:", f1_score(y_test, y_test_pred))

from sklearn.naive_bayes import GaussianNB

nb_model = GaussianNB()
nb_model.fit(X_train, y_train)

y_train_pred = nb_model.predict(X_train)
y_test_pred = nb_model.predict(X_test)

print("\nðŸ“˜ Naive Bayes:")
print("Train - Accuracy:", accuracy_score(y_train, y_train_pred))
print("Train - Precision:", precision_score(y_train, y_train_pred))
print("Train - F1 Score:", f1_score(y_train, y_train_pred))
print("Test  - Accuracy:", accuracy_score(y_test, y_test_pred))
print("Test  - Precision:", precision_score(y_test, y_test_pred))
print("Test  - F1 Score:", f1_score(y_test, y_test_pred))

from sklearn.ensemble import GradientBoostingClassifier

gb_model = GradientBoostingClassifier(random_state=2)
gb_model.fit(X_train, y_train)

y_train_pred = gb_model.predict(X_train)
y_test_pred = gb_model.predict(X_test)

print("ðŸ“˜ Gradient Boosting:")
print("Train - Accuracy:", accuracy_score(y_train, y_train_pred))
print("Train - Precision:", precision_score(y_train, y_train_pred))
print("Train - F1 Score:", f1_score(y_train, y_train_pred))
print("Test  - Accuracy:", accuracy_score(y_test, y_test_pred))
print("Test  - Precision:", precision_score(y_test, y_test_pred))
print("Test  - F1 Score:", f1_score(y_test, y_test_pred))

from sklearn.ensemble import GradientBoostingClassifier
from sklearn.metrics import accuracy_score
import matplotlib.pyplot as plt

train_accuracies = []
test_accuracies = []
n_estimators_range = range(10, 201, 10)

for n in n_estimators_range:
    gb_model = GradientBoostingClassifier(n_estimators=n, random_state=2)
    gb_model.fit(X_train, y_train)
    train_accuracies.append(accuracy_score(y_train, gb_model.predict(X_train)))
    test_accuracies.append(accuracy_score(y_test, gb_model.predict(X_test)))

plt.figure(figsize=(10, 6))
plt.plot(n_estimators_range, train_accuracies, label='Train Accuracy', marker='o')
plt.plot(n_estimators_range, test_accuracies, label='Test Accuracy', marker='s')
plt.xlabel('Number of Estimators (K)')
plt.ylabel('Accuracy')
plt.title('Gradient Boosting Accuracy vs Number of Estimators')
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.show()

from sklearn.metrics import roc_curve, roc_auc_score

# Use final model
gb_model = GradientBoostingClassifier(random_state=2)
gb_model.fit(X_train, y_train)

# Predict probabilities
y_proba = gb_model.predict_proba(X_test)[:, 1]

# ROC curve
fpr, tpr, _ = roc_curve(y_test, y_proba)
auc = roc_auc_score(y_test, y_proba)

plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, label=f"AUC = {auc:.2f}")
plt.plot([0, 1], [0, 1], 'k--', label='Random Guess')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve - Gradient Boosting')
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.show()

from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay

# Predict classes
y_pred = gb_model.predict(X_test)

# Confusion Matrix
cm = confusion_matrix(y_test, y_pred)
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=["Non-Diabetic", "Diabetic"])
disp.plot(cmap='Blues')
plt.title("Confusion Matrix - Gradient Boosting")
plt.grid(False)
plt.tight_layout()
plt.show()

# Extended dictionary with all models
models = {
    'Logistic Regression': logreg_model,
    'KNN': knn_model,
    'Random Forest': rf_model,
    'SVM': classifier,
    'Gradient Boosting': gb_model,
    'Naive Bayes': nb_model,
    'XGBoost': xgb_model
}

# Collecting metrics
results = []
for name, model in models.items():
    y_train_pred = model.predict(X_train)
    y_test_pred = model.predict(X_test)

    results.append({
        'Model': name,
        'Train Accuracy': round(accuracy_score(y_train, y_train_pred), 4),
        'Train Precision': round(precision_score(y_train, y_train_pred), 4),
        'Train F1-Score': round(f1_score(y_train, y_train_pred), 4),
        'Test Accuracy': round(accuracy_score(y_test, y_test_pred), 4),
        'Test Precision': round(precision_score(y_test, y_test_pred), 4),
        'Test F1-Score': round(f1_score(y_test, y_test_pred), 4)
    })

# Create DataFrame
results_df = pd.DataFrame(results)

# Clean 2D tabular output
print("\nðŸ“Š Model Performance Summary:")
print(results_df.set_index('Model'))

